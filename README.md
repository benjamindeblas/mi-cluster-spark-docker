# mi-cluster-spark-docker
En este repositorio, documento los pasos para configurar un clúster Spark con Docker. El clúster es una pequeña red local (LAN) de hasta 20 nodos con el objetivo de procesar 1 TB de datos en más de una hora y media. Este no es un proyecto de producción, sino un experimento para aprender un poco sobre estas tecnologías y compartir lo aprendido.


## Objetivo

En este repositorio documentaré los pasos para configurar un cluster Spark usando Docker. 
El cluster tendrá hasta X nodos con el objetivo de procesar datos [describe tu caso de uso].

Este es un proyecto [experimental/de aprendizaje/de producción] para aprender sobre estas tecnologías.

## Estado del proyecto

- [ ] Documentación completa
- [ ] Configuración básica
- [ ] Pruebas iniciales
- [ ] Optimizaciones

## Cómo usar

1. Clona el repositorio
2. Ejecuta `./setup_swarm.sh`
3. [Otros pasos...]
